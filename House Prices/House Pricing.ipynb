{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b665bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e6feeb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Kaggle/House Prices/train.csv')\n",
    "test = pd.read_csv('/Kaggle/House Prices/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f5bde92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>350</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>118000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "5   6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
       "6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
       "7   8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
       "8   9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
       "9  10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "5         Lvl    AllPub  ...        0    NaN  MnPrv        Shed     700   \n",
       "6         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "7         Lvl    AllPub  ...        0    NaN    NaN        Shed     350   \n",
       "8         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "9         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "5     10   2009        WD         Normal     143000  \n",
       "6      8   2007        WD         Normal     307000  \n",
       "7     11   2009        WD         Normal     200000  \n",
       "8      4   2008        WD        Abnorml     129900  \n",
       "9      1   2008        WD         Normal     118000  \n",
       "\n",
       "[10 rows x 81 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e30cd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f4c400cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMissingColDetails(data):\n",
    "    for col in data.columns:\n",
    "        if(data[col].isna().any()):\n",
    "            print(f'{col}: {data[col].isna().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "36d39b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getMissingColDetails(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe1b1ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getMissingColDetails(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "76b1df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['Alley', 'PoolQC', 'Fence', 'MiscFeature'], axis=1)\n",
    "test = test.drop(columns=['Alley', 'PoolQC', 'Fence', 'MiscFeature'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "228a83f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getMissingColDetails(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "291ad383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4d316777",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = train.select_dtypes(include=np.number).columns.tolist()\n",
    "numeric_cols.remove(numeric_cols[-1])\n",
    "\n",
    "alpha_cols = train.select_dtypes(exclude=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6e7b58c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9bb463fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_cols:\n",
    "    train[col].fillna(train[col].mean(), inplace=True)\n",
    "    test[col].fillna(test[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6fac57a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning: 4\n",
      "Utilities: 2\n",
      "Exterior1st: 1\n",
      "Exterior2nd: 1\n",
      "MasVnrType: 16\n",
      "BsmtQual: 44\n",
      "BsmtCond: 45\n",
      "BsmtExposure: 44\n",
      "BsmtFinType1: 42\n",
      "BsmtFinType2: 42\n",
      "KitchenQual: 1\n",
      "Functional: 2\n",
      "FireplaceQu: 730\n",
      "GarageType: 76\n",
      "GarageFinish: 78\n",
      "GarageQual: 78\n",
      "GarageCond: 78\n",
      "SaleType: 1\n"
     ]
    }
   ],
   "source": [
    "getMissingColDetails(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fc5c8462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSZoning\n",
      "RL         1151\n",
      "RM          218\n",
      "FV           65\n",
      "RH           16\n",
      "C (all)      10\n",
      "Name: MSZoning, dtype: int64\n",
      "\n",
      "Street\n",
      "Pave    1454\n",
      "Grvl       6\n",
      "Name: Street, dtype: int64\n",
      "\n",
      "LotShape\n",
      "Reg    925\n",
      "IR1    484\n",
      "IR2     41\n",
      "IR3     10\n",
      "Name: LotShape, dtype: int64\n",
      "\n",
      "LandContour\n",
      "Lvl    1311\n",
      "Bnk      63\n",
      "HLS      50\n",
      "Low      36\n",
      "Name: LandContour, dtype: int64\n",
      "\n",
      "Utilities\n",
      "AllPub    1459\n",
      "NoSeWa       1\n",
      "Name: Utilities, dtype: int64\n",
      "\n",
      "LotConfig\n",
      "Inside     1052\n",
      "Corner      263\n",
      "CulDSac      94\n",
      "FR2          47\n",
      "FR3           4\n",
      "Name: LotConfig, dtype: int64\n",
      "\n",
      "LandSlope\n",
      "Gtl    1382\n",
      "Mod      65\n",
      "Sev      13\n",
      "Name: LandSlope, dtype: int64\n",
      "\n",
      "Neighborhood\n",
      "NAmes      225\n",
      "CollgCr    150\n",
      "OldTown    113\n",
      "Edwards    100\n",
      "Somerst     86\n",
      "Gilbert     79\n",
      "NridgHt     77\n",
      "Sawyer      74\n",
      "NWAmes      73\n",
      "SawyerW     59\n",
      "BrkSide     58\n",
      "Crawfor     51\n",
      "Mitchel     49\n",
      "NoRidge     41\n",
      "Timber      38\n",
      "IDOTRR      37\n",
      "ClearCr     28\n",
      "SWISU       25\n",
      "StoneBr     25\n",
      "MeadowV     17\n",
      "Blmngtn     17\n",
      "BrDale      16\n",
      "Veenker     11\n",
      "NPkVill      9\n",
      "Blueste      2\n",
      "Name: Neighborhood, dtype: int64\n",
      "\n",
      "Condition1\n",
      "Norm      1260\n",
      "Feedr       81\n",
      "Artery      48\n",
      "RRAn        26\n",
      "PosN        19\n",
      "RRAe        11\n",
      "PosA         8\n",
      "RRNn         5\n",
      "RRNe         2\n",
      "Name: Condition1, dtype: int64\n",
      "\n",
      "Condition2\n",
      "Norm      1445\n",
      "Feedr        6\n",
      "PosN         2\n",
      "RRNn         2\n",
      "Artery       2\n",
      "RRAe         1\n",
      "PosA         1\n",
      "RRAn         1\n",
      "Name: Condition2, dtype: int64\n",
      "\n",
      "BldgType\n",
      "1Fam      1220\n",
      "TwnhsE     114\n",
      "Duplex      52\n",
      "Twnhs       43\n",
      "2fmCon      31\n",
      "Name: BldgType, dtype: int64\n",
      "\n",
      "HouseStyle\n",
      "1Story    726\n",
      "2Story    445\n",
      "1.5Fin    154\n",
      "SLvl       65\n",
      "SFoyer     37\n",
      "1.5Unf     14\n",
      "2.5Unf     11\n",
      "2.5Fin      8\n",
      "Name: HouseStyle, dtype: int64\n",
      "\n",
      "RoofStyle\n",
      "Gable      1141\n",
      "Hip         286\n",
      "Flat         13\n",
      "Gambrel      11\n",
      "Mansard       7\n",
      "Shed          2\n",
      "Name: RoofStyle, dtype: int64\n",
      "\n",
      "RoofMatl\n",
      "CompShg    1434\n",
      "Tar&Grv      11\n",
      "WdShngl       6\n",
      "WdShake       5\n",
      "Roll          1\n",
      "ClyTile       1\n",
      "Membran       1\n",
      "Metal         1\n",
      "Name: RoofMatl, dtype: int64\n",
      "\n",
      "Exterior1st\n",
      "VinylSd    515\n",
      "HdBoard    222\n",
      "MetalSd    220\n",
      "Wd Sdng    206\n",
      "Plywood    108\n",
      "CemntBd     61\n",
      "BrkFace     50\n",
      "WdShing     26\n",
      "Stucco      25\n",
      "AsbShng     20\n",
      "BrkComm      2\n",
      "Stone        2\n",
      "CBlock       1\n",
      "AsphShn      1\n",
      "ImStucc      1\n",
      "Name: Exterior1st, dtype: int64\n",
      "\n",
      "Exterior2nd\n",
      "VinylSd    504\n",
      "MetalSd    214\n",
      "HdBoard    207\n",
      "Wd Sdng    197\n",
      "Plywood    142\n",
      "CmentBd     60\n",
      "Wd Shng     38\n",
      "Stucco      26\n",
      "BrkFace     25\n",
      "AsbShng     20\n",
      "ImStucc     10\n",
      "Brk Cmn      7\n",
      "Stone        5\n",
      "AsphShn      3\n",
      "CBlock       1\n",
      "Other        1\n",
      "Name: Exterior2nd, dtype: int64\n",
      "\n",
      "MasVnrType\n",
      "None       864\n",
      "BrkFace    445\n",
      "Stone      128\n",
      "BrkCmn      15\n",
      "Name: MasVnrType, dtype: int64\n",
      "\n",
      "ExterQual\n",
      "TA    906\n",
      "Gd    488\n",
      "Ex     52\n",
      "Fa     14\n",
      "Name: ExterQual, dtype: int64\n",
      "\n",
      "ExterCond\n",
      "TA    1282\n",
      "Gd     146\n",
      "Fa      28\n",
      "Ex       3\n",
      "Po       1\n",
      "Name: ExterCond, dtype: int64\n",
      "\n",
      "Foundation\n",
      "PConc     647\n",
      "CBlock    634\n",
      "BrkTil    146\n",
      "Slab       24\n",
      "Stone       6\n",
      "Wood        3\n",
      "Name: Foundation, dtype: int64\n",
      "\n",
      "BsmtQual\n",
      "TA    649\n",
      "Gd    618\n",
      "Ex    121\n",
      "Fa     35\n",
      "Name: BsmtQual, dtype: int64\n",
      "\n",
      "BsmtCond\n",
      "TA    1311\n",
      "Gd      65\n",
      "Fa      45\n",
      "Po       2\n",
      "Name: BsmtCond, dtype: int64\n",
      "\n",
      "BsmtExposure\n",
      "No    953\n",
      "Av    221\n",
      "Gd    134\n",
      "Mn    114\n",
      "Name: BsmtExposure, dtype: int64\n",
      "\n",
      "BsmtFinType1\n",
      "Unf    430\n",
      "GLQ    418\n",
      "ALQ    220\n",
      "BLQ    148\n",
      "Rec    133\n",
      "LwQ     74\n",
      "Name: BsmtFinType1, dtype: int64\n",
      "\n",
      "BsmtFinType2\n",
      "Unf    1256\n",
      "Rec      54\n",
      "LwQ      46\n",
      "BLQ      33\n",
      "ALQ      19\n",
      "GLQ      14\n",
      "Name: BsmtFinType2, dtype: int64\n",
      "\n",
      "Heating\n",
      "GasA     1428\n",
      "GasW       18\n",
      "Grav        7\n",
      "Wall        4\n",
      "OthW        2\n",
      "Floor       1\n",
      "Name: Heating, dtype: int64\n",
      "\n",
      "HeatingQC\n",
      "Ex    741\n",
      "TA    428\n",
      "Gd    241\n",
      "Fa     49\n",
      "Po      1\n",
      "Name: HeatingQC, dtype: int64\n",
      "\n",
      "CentralAir\n",
      "Y    1365\n",
      "N      95\n",
      "Name: CentralAir, dtype: int64\n",
      "\n",
      "Electrical\n",
      "SBrkr    1334\n",
      "FuseA      94\n",
      "FuseF      27\n",
      "FuseP       3\n",
      "Mix         1\n",
      "Name: Electrical, dtype: int64\n",
      "\n",
      "KitchenQual\n",
      "TA    735\n",
      "Gd    586\n",
      "Ex    100\n",
      "Fa     39\n",
      "Name: KitchenQual, dtype: int64\n",
      "\n",
      "Functional\n",
      "Typ     1360\n",
      "Min2      34\n",
      "Min1      31\n",
      "Mod       15\n",
      "Maj1      14\n",
      "Maj2       5\n",
      "Sev        1\n",
      "Name: Functional, dtype: int64\n",
      "\n",
      "FireplaceQu\n",
      "Gd    380\n",
      "TA    313\n",
      "Fa     33\n",
      "Ex     24\n",
      "Po     20\n",
      "Name: FireplaceQu, dtype: int64\n",
      "\n",
      "GarageType\n",
      "Attchd     870\n",
      "Detchd     387\n",
      "BuiltIn     88\n",
      "Basment     19\n",
      "CarPort      9\n",
      "2Types       6\n",
      "Name: GarageType, dtype: int64\n",
      "\n",
      "GarageFinish\n",
      "Unf    605\n",
      "RFn    422\n",
      "Fin    352\n",
      "Name: GarageFinish, dtype: int64\n",
      "\n",
      "GarageQual\n",
      "TA    1311\n",
      "Fa      48\n",
      "Gd      14\n",
      "Ex       3\n",
      "Po       3\n",
      "Name: GarageQual, dtype: int64\n",
      "\n",
      "GarageCond\n",
      "TA    1326\n",
      "Fa      35\n",
      "Gd       9\n",
      "Po       7\n",
      "Ex       2\n",
      "Name: GarageCond, dtype: int64\n",
      "\n",
      "PavedDrive\n",
      "Y    1340\n",
      "N      90\n",
      "P      30\n",
      "Name: PavedDrive, dtype: int64\n",
      "\n",
      "SaleType\n",
      "WD       1267\n",
      "New       122\n",
      "COD        43\n",
      "ConLD       9\n",
      "ConLw       5\n",
      "ConLI       5\n",
      "CWD         4\n",
      "Oth         3\n",
      "Con         2\n",
      "Name: SaleType, dtype: int64\n",
      "\n",
      "SaleCondition\n",
      "Normal     1198\n",
      "Partial     125\n",
      "Abnorml     101\n",
      "Family       20\n",
      "Alloca       12\n",
      "AdjLand       4\n",
      "Name: SaleCondition, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in alpha_cols:\n",
    "    print(f'\\n{col}')\n",
    "    print(train[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4c3a149d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Normal'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SaleCondition.mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bf2f5d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gd    380\n",
       "TA    313\n",
       "Fa     33\n",
       "Ex     24\n",
       "Po     20\n",
       "Name: FireplaceQu, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.FireplaceQu.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c722d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unf    605\n",
       "RFn    422\n",
       "Fin    352\n",
       "Name: GarageFinish, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.GarageFinish.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "93375667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anirb\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='HeatingQC', ylabel='count'>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train.HeatingQC, hue=train.GarageFinish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f45dd071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anirb\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='BsmtQual', ylabel='count'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train.BsmtQual, hue=train.FireplaceQu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "89dfe671",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqList = ['FireplaceQu', 'GarageFinish']\n",
    "alpha_cols_temp = list(set(alpha_cols) - set(eqList))\n",
    "for col in alpha_cols_temp:\n",
    "    train[col].fillna(train[col].mode()[0], inplace=True)\n",
    "    test[col].fillna(test[col].mode()[0], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "20b06c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FireplaceQu: 690\n",
      "GarageFinish: 81\n"
     ]
    }
   ],
   "source": [
    "getMissingColDetails(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132d5a4f",
   "metadata": {},
   "source": [
    "## Filling NA values for 'FireplaceQu', 'GarageFinish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fb278c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TA    686\n",
       "Gd    618\n",
       "Ex    121\n",
       "Fa     35\n",
       "Name: BsmtQual, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.BsmtQual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7b52956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618\n",
      "842\n"
     ]
    }
   ],
   "source": [
    "a=b=0\n",
    "for i in train['BsmtQual']:\n",
    "    if(i == 'Gd'):\n",
    "        a = a+1\n",
    "    else:\n",
    "        b = b+1\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3ad09208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TA    409\n",
       "Gd    238\n",
       "Fa     27\n",
       "Ex     16\n",
       "Name: BsmtQual, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bruh = train[train.FireplaceQu.isna()]\n",
    "bruh['BsmtQual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9e945749",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_train = train.copy()\n",
    "#fire_train = FillFireplaceQuValue(fire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "866dd4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gd    380\n",
       "TA    313\n",
       "Fa     33\n",
       "Ex     24\n",
       "Po     20\n",
       "Name: FireplaceQu, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.FireplaceQu.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "58e435f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gd    380\n",
       "TA    313\n",
       "Fa     33\n",
       "Ex     24\n",
       "Po     20\n",
       "Name: FireplaceQu, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_train.FireplaceQu.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cb050db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TA    445\n",
       "Gd    153\n",
       "Fa     11\n",
       "Po      5\n",
       "Ex      4\n",
       "Name: FireplaceQu, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bsmt_gd.FireplaceQu.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "33741c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: FireplaceQu, dtype: int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bsmt_gd.FireplaceQu.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aa0b90c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>11200</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>12968</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>1453</td>\n",
       "      <td>180</td>\n",
       "      <td>RM</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>3675</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>1454</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>17217</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>84500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1455</td>\n",
       "      <td>20</td>\n",
       "      <td>FV</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>7500</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  \\\n",
       "0        1          60       RL    65.000000     8450   Pave      Reg   \n",
       "5        6          50       RL    85.000000    14115   Pave      IR1   \n",
       "10      11          20       RL    70.000000    11200   Pave      Reg   \n",
       "12      13          20       RL    70.049958    12968   Pave      IR2   \n",
       "15      16          45       RM    51.000000     6120   Pave      Reg   \n",
       "...    ...         ...      ...          ...      ...    ...      ...   \n",
       "1452  1453         180       RM    35.000000     3675   Pave      Reg   \n",
       "1453  1454          20       RL    90.000000    17217   Pave      Reg   \n",
       "1454  1455          20       FV    62.000000     7500   Pave      Reg   \n",
       "1458  1459          20       RL    68.000000     9717   Pave      Reg   \n",
       "1459  1460          20       RL    75.000000     9937   Pave      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0            Lvl    AllPub    Inside  ...             0         0           0   \n",
       "5            Lvl    AllPub    Inside  ...             0       320           0   \n",
       "10           Lvl    AllPub    Inside  ...             0         0           0   \n",
       "12           Lvl    AllPub    Inside  ...             0         0         176   \n",
       "15           Lvl    AllPub    Corner  ...             0         0           0   \n",
       "...          ...       ...       ...  ...           ...       ...         ...   \n",
       "1452         Lvl    AllPub    Inside  ...             0         0           0   \n",
       "1453         Lvl    AllPub    Inside  ...             0         0           0   \n",
       "1454         Lvl    AllPub    Inside  ...             0         0           0   \n",
       "1458         Lvl    AllPub    Inside  ...           112         0           0   \n",
       "1459         Lvl    AllPub    Inside  ...             0         0           0   \n",
       "\n",
       "     PoolArea MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0           0       0      2    2008        WD         Normal     208500  \n",
       "5           0     700     10    2009        WD         Normal     143000  \n",
       "10          0       0      2    2008        WD         Normal     129500  \n",
       "12          0       0      9    2008        WD         Normal     144000  \n",
       "15          0       0      7    2007        WD         Normal     132000  \n",
       "...       ...     ...    ...     ...       ...            ...        ...  \n",
       "1452        0       0      5    2006        WD         Normal     145000  \n",
       "1453        0       0      7    2006        WD        Abnorml      84500  \n",
       "1454        0       0     10    2009        WD         Normal     185000  \n",
       "1458        0       0      4    2010        WD         Normal     142125  \n",
       "1459        0       0      6    2008        WD         Normal     147500  \n",
       "\n",
       "[690 rows x 77 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_train[fire_train.FireplaceQu.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a060be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bsmt_gd = fire_train[fire_train.FireplaceQu.isna()]\n",
    "Bsmt_gd['FireplaceQu'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22bb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c802a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FillFireplaceQuValue(data):\n",
    "    Bsmt_Gd_data = data[data.BsmtQual == 'Gd']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in data['BsmtQual']:\n",
    "        if(i == 'Gd'):\n",
    "            data['FireplaceQu'].fillna('TA', inplace=True)\n",
    "        else:\n",
    "            data['FireplaceQu'].fillna('Gd', inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33c64d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test['BsmtQual']:\n",
    "    if(i == 'Gd'):\n",
    "        test['FireplaceQu'].fillna('TA', inplace=True)\n",
    "    else:\n",
    "        test['FireplaceQu'].fillna('Gd', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15ad97c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train['HeatingQC']:\n",
    "    if(i == 'Ex'):\n",
    "        train['GarageFinish'].fillna('RFn', inplace=True)\n",
    "    else:\n",
    "        train['GarageFinish'].fillna('Unf', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfd6bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test['HeatingQC']:\n",
    "    if(i == 'Ex'):\n",
    "        test['GarageFinish'].fillna('RFn', inplace=True)\n",
    "    else:\n",
    "        test['GarageFinish'].fillna('Unf', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25dd8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "getMissingColDetails(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "28e9db71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gd    380\n",
       "TA    313\n",
       "Fa     33\n",
       "Ex     24\n",
       "Po     20\n",
       "Name: FireplaceQu, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.FireplaceQu.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b47da61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unf    605\n",
       "RFn    422\n",
       "Fin    352\n",
       "Name: GarageFinish, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.GarageFinish.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "94805169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.FireplaceQu.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb158a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anirb\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='TotRmsAbvGrd', ylabel='count'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train.TotRmsAbvGrd, hue=train.FireplaceQu, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff755f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0cb62ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in alpha_cols:\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.fit_transform(test[col])\n",
    "    #print(f\"{col}: {le.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "030a9974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    1003\n",
       "2     380\n",
       "1      33\n",
       "0      24\n",
       "3      20\n",
       "Name: FireplaceQu, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.FireplaceQu.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c2af6765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
       "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
       "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
       "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
       "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
       "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
       "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
       "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
       "       'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
       "       'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond',\n",
       "       'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "93406135",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dict = {}\n",
    "for col in train.columns:\n",
    "    corr_dict[col] = train['SalePrice'].corr(train[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eafc47",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f4f40e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4a64b926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GradientBoostingRegressor in module sklearn.ensemble._gb:\n",
      "\n",
      "class GradientBoostingRegressor(sklearn.base.RegressorMixin, BaseGradientBoosting)\n",
      " |  GradientBoostingRegressor(*, loss='ls', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
      " |  \n",
      " |  Gradient Boosting for regression.\n",
      " |  \n",
      " |  GB builds an additive model in a forward stage-wise fashion;\n",
      " |  it allows for the optimization of arbitrary differentiable loss functions.\n",
      " |  In each stage a regression tree is fit on the negative gradient of the\n",
      " |  given loss function.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <gradient_boosting>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  loss : {'ls', 'lad', 'huber', 'quantile'}, default='ls'\n",
      " |      Loss function to be optimized. 'ls' refers to least squares\n",
      " |      regression. 'lad' (least absolute deviation) is a highly robust\n",
      " |      loss function solely based on order information of the input\n",
      " |      variables. 'huber' is a combination of the two. 'quantile'\n",
      " |      allows quantile regression (use `alpha` to specify the quantile).\n",
      " |  \n",
      " |  learning_rate : float, default=0.1\n",
      " |      Learning rate shrinks the contribution of each tree by `learning_rate`.\n",
      " |      There is a trade-off between learning_rate and n_estimators.\n",
      " |  \n",
      " |  n_estimators : int, default=100\n",
      " |      The number of boosting stages to perform. Gradient boosting\n",
      " |      is fairly robust to over-fitting so a large number usually\n",
      " |      results in better performance.\n",
      " |  \n",
      " |  subsample : float, default=1.0\n",
      " |      The fraction of samples to be used for fitting the individual base\n",
      " |      learners. If smaller than 1.0 this results in Stochastic Gradient\n",
      " |      Boosting. `subsample` interacts with the parameter `n_estimators`.\n",
      " |      Choosing `subsample < 1.0` leads to a reduction of variance\n",
      " |      and an increase in bias.\n",
      " |  \n",
      " |  criterion : {'friedman_mse', 'mse', 'mae'}, default='friedman_mse'\n",
      " |      The function to measure the quality of a split. Supported criteria\n",
      " |      are \"friedman_mse\" for the mean squared error with improvement\n",
      " |      score by Friedman, \"mse\" for mean squared error, and \"mae\" for\n",
      " |      the mean absolute error. The default value of \"friedman_mse\" is\n",
      " |      generally the best as it can provide a better approximation in\n",
      " |      some cases.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |      .. deprecated:: 0.24\n",
      " |          `criterion='mae'` is deprecated and will be removed in version\n",
      " |          1.1 (renaming of 0.26). The correct way of minimizing the absolute\n",
      " |          error is to use `loss='lad'` instead.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_depth : int, default=3\n",
      " |      Maximum depth of the individual regression estimators. The maximum\n",
      " |      depth limits the number of nodes in the tree. Tune this parameter\n",
      " |      for best performance; the best value depends on the interaction\n",
      " |      of the input variables.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float, default=None\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
      " |         ``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\n",
      " |         will be removed in 1.0 (renaming of 0.25).\n",
      " |         Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  init : estimator or 'zero', default=None\n",
      " |      An estimator object that is used to compute the initial predictions.\n",
      " |      ``init`` has to provide :term:`fit` and :term:`predict`. If 'zero', the\n",
      " |      initial raw predictions are set to zero. By default a\n",
      " |      ``DummyEstimator`` is used, predicting either the average target value\n",
      " |      (for loss='ls'), or a quantile for the other losses.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the random seed given to each Tree estimator at each\n",
      " |      boosting iteration.\n",
      " |      In addition, it controls the random permutation of the features at\n",
      " |      each split (see Notes for more details).\n",
      " |      It also controls the random spliting of the training data to obtain a\n",
      " |      validation set if `n_iter_no_change` is not None.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  max_features : {'auto', 'sqrt', 'log2'}, int or float, default=None\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `int(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=n_features`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Choosing `max_features < n_features` leads to a reduction of variance\n",
      " |      and an increase in bias.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  alpha : float, default=0.9\n",
      " |      The alpha-quantile of the huber loss function and the quantile\n",
      " |      loss function. Only if ``loss='huber'`` or ``loss='quantile'``.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Enable verbose output. If 1 then it prints progress and performance\n",
      " |      once in a while (the more trees the lower the frequency). If greater\n",
      " |      than 1 then it prints progress and performance for every tree.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just erase the\n",
      " |      previous solution. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  validation_fraction : float, default=0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Must be between 0 and 1.\n",
      " |      Only used if ``n_iter_no_change`` is set to an integer.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  n_iter_no_change : int, default=None\n",
      " |      ``n_iter_no_change`` is used to decide if early stopping will be used\n",
      " |      to terminate training when validation score is not improving. By\n",
      " |      default it is set to None to disable early stopping. If set to a\n",
      " |      number, it will set aside ``validation_fraction`` size of the training\n",
      " |      data as validation and terminate training when validation score is not\n",
      " |      improving in all of the previous ``n_iter_no_change`` numbers of\n",
      " |      iterations.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for the early stopping. When the loss is not improving\n",
      " |      by at least tol for ``n_iter_no_change`` iterations (if set to a\n",
      " |      number), the training stops.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  oob_improvement_ : ndarray of shape (n_estimators,)\n",
      " |      The improvement in loss (= deviance) on the out-of-bag samples\n",
      " |      relative to the previous iteration.\n",
      " |      ``oob_improvement_[0]`` is the improvement in\n",
      " |      loss of the first stage over the ``init`` estimator.\n",
      " |      Only available if ``subsample < 1.0``\n",
      " |  \n",
      " |  train_score_ : ndarray of shape (n_estimators,)\n",
      " |      The i-th score ``train_score_[i]`` is the deviance (= loss) of the\n",
      " |      model at iteration ``i`` on the in-bag sample.\n",
      " |      If ``subsample == 1`` this is the deviance on the training data.\n",
      " |  \n",
      " |  loss_ : LossFunction\n",
      " |      The concrete ``LossFunction`` object.\n",
      " |  \n",
      " |  init_ : estimator\n",
      " |      The estimator that provides the initial predictions.\n",
      " |      Set via the ``init`` argument or ``loss.init_estimator``.\n",
      " |  \n",
      " |  estimators_ : ndarray of DecisionTreeRegressor of shape (n_estimators, 1)\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  n_classes_ : int\n",
      " |      The number of classes, set to 1 for regressors.\n",
      " |  \n",
      " |      .. deprecated:: 0.24\n",
      " |          Attribute ``n_classes_`` was deprecated in version 0.24 and\n",
      " |          will be removed in 1.1 (renaming of 0.26).\n",
      " |  \n",
      " |  n_estimators_ : int\n",
      " |      The number of estimators as selected by early stopping (if\n",
      " |      ``n_iter_no_change`` is specified). Otherwise it is set to\n",
      " |      ``n_estimators``.\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of data features.\n",
      " |  \n",
      " |  max_features_ : int\n",
      " |      The inferred value of max_features.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  HistGradientBoostingRegressor : Histogram-based Gradient Boosting\n",
      " |      Classification Tree.\n",
      " |  sklearn.tree.DecisionTreeRegressor : A decision tree regressor.\n",
      " |  sklearn.tree.RandomForestRegressor : A random forest regressor.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data and\n",
      " |  ``max_features=n_features``, if the improvement of the criterion is\n",
      " |  identical for several splits enumerated during the search of the best\n",
      " |  split. To obtain a deterministic behaviour during fitting,\n",
      " |  ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import make_regression\n",
      " |  >>> from sklearn.ensemble import GradientBoostingRegressor\n",
      " |  >>> from sklearn.model_selection import train_test_split\n",
      " |  >>> X, y = make_regression(random_state=0)\n",
      " |  >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      " |  ...     X, y, random_state=0)\n",
      " |  >>> reg = GradientBoostingRegressor(random_state=0)\n",
      " |  >>> reg.fit(X_train, y_train)\n",
      " |  GradientBoostingRegressor(random_state=0)\n",
      " |  >>> reg.predict(X_test[1:2])\n",
      " |  array([-61...])\n",
      " |  >>> reg.score(X_test, y_test)\n",
      " |  0.4...\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  J. Friedman, Greedy Function Approximation: A Gradient Boosting\n",
      " |  Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.\n",
      " |  \n",
      " |  J. Friedman, Stochastic Gradient Boosting, 1999\n",
      " |  \n",
      " |  T. Hastie, R. Tibshirani and J. Friedman.\n",
      " |  Elements of Statistical Learning Ed. 2, Springer, 2009.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GradientBoostingRegressor\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      BaseGradientBoosting\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, loss='ls', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the ensemble to X, return leaf indices.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will\n",
      " |          be converted to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array-like of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the ensemble,\n",
      " |          return the index of the leaf x ends up in each estimator.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict regression target for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  staged_predict(self, X)\n",
      " |      Predict regression target at each stage for X.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each stage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : generator of ndarray of shape (n_samples,)\n",
      " |          The predicted value of the input samples.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  n_classes_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination :math:`R^2` of the\n",
      " |      prediction.\n",
      " |      \n",
      " |      The coefficient :math:`R^2` is defined as :math:`(1 - \\frac{u}{v})`,\n",
      " |      where :math:`u` is the residual sum of squares ``((y_true - y_pred)\n",
      " |      ** 2).sum()`` and :math:`v` is the total sum of squares ``((y_true -\n",
      " |      y_true.mean()) ** 2).sum()``. The best possible score is 1.0 and it\n",
      " |      can be negative (because the model can be arbitrarily worse). A\n",
      " |      constant model that always predicts the expected value of `y`,\n",
      " |      disregarding the input features, would get a :math:`R^2` score of\n",
      " |      0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseGradientBoosting:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, monitor=None)\n",
      " |      Fit the gradient boosting model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (strings or integers in classification, real numbers\n",
      " |          in regression)\n",
      " |          For classification, labels must correspond to classes.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      monitor : callable, default=None\n",
      " |          The monitor is called after each iteration with the current\n",
      " |          iteration, a reference to the estimator and the local variables of\n",
      " |          ``_fit_stages`` as keyword arguments ``callable(i, self,\n",
      " |          locals())``. If the callable returns ``True`` the fitting procedure\n",
      " |          is stopped. The monitor can be used for various things such as\n",
      " |          computing held-out estimates, early stopping, model introspect, and\n",
      " |          snapshoting.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseGradientBoosting:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __annotations__ = {'_required_parameters': typing.List[str]}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GradientBoostingRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f85157f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(\"SalePrice\", axis = 1)\n",
    "y = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3045dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e7774c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a7aa9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\": [i for i in range(1, 200, 5)],\n",
    "              'max_depth': [i for i in range (1, 10, 1)]\n",
    "             }\n",
    "    \n",
    "gb_model = GradientBoostingRegressor()\n",
    "grid = GridSearchCV(gb_model,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "441ae1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid1 = {\"n_estimators\": [i for i in range(120, 200, 5)],\n",
    "              'max_depth': [i for i in range (1, 5, 1)],\n",
    "              'alpha': [0.2, 0.4, 0.6, 0.7, 0.8, 0.9]\n",
    "             }\n",
    "    \n",
    "gb_model = GradientBoostingRegressor()\n",
    "grid1 = GridSearchCV(gb_model,param_grid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c99c4d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingRegressor(),\n",
       "             param_grid={'alpha': [0.2, 0.4, 0.6, 0.7, 0.8, 0.9],\n",
       "                         'max_depth': [1, 2, 3, 4],\n",
       "                         'n_estimators': [120, 125, 130, 135, 140, 145, 150,\n",
       "                                          155, 160, 165, 170, 175, 180, 185,\n",
       "                                          190, 195]})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ab5a46e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.6, 'max_depth': 4, 'n_estimators': 170}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "29e42030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.8, 'max_depth': 2, 'n_estimators': 160}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a39f305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(**grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e913f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "53f1e299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34158.42458840756"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e94aaaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34158.42458840756"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4f763014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180921.19589041095"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SalePrice.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2b718732",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = grid.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "19eb5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame({'Id': test.Id,\n",
    "                        'SalePrice': submission})\n",
    "df_final.to_csv('E:\\Kaggle\\House Prices\\Submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff501d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695fbb69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e426429",
   "metadata": {},
   "source": [
    "## Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d3b8ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8c4f132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestRegressor in module sklearn.ensemble._forest:\n",
      "\n",
      "class RandomForestRegressor(ForestRegressor)\n",
      " |  RandomForestRegressor(n_estimators=100, *, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
      " |  \n",
      " |  A random forest regressor.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of classifying\n",
      " |  decision trees on various sub-samples of the dataset and uses averaging\n",
      " |  to improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
      " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      " |  each tree.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : int, default=100\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``n_estimators`` changed from 10 to 100\n",
      " |         in 0.22.\n",
      " |  \n",
      " |  criterion : {\"mse\", \"mae\"}, default=\"mse\"\n",
      " |      The function to measure the quality of a split. Supported criteria\n",
      " |      are \"mse\" for the mean squared error, which is equal to variance\n",
      " |      reduction as feature selection criterion, and \"mae\" for the mean\n",
      " |      absolute error.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Mean Absolute Error (MAE) criterion.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : {\"auto\", \"sqrt\", \"log2\"}, int or float, default=\"auto\"\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `round(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=n_features`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float, default=None\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
      " |         ``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\n",
      " |         will be removed in 1.0 (renaming of 0.25).\n",
      " |         Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  bootstrap : bool, default=True\n",
      " |      Whether bootstrap samples are used when building trees. If False, the\n",
      " |      whole dataset is used to build each tree.\n",
      " |  \n",
      " |  oob_score : bool, default=False\n",
      " |      whether to use out-of-bag samples to estimate\n",
      " |      the R^2 on unseen data.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
      " |      <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls both the randomness of the bootstrapping of the samples used\n",
      " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
      " |      features to consider when looking for the best split at each node\n",
      " |      (if ``max_features < n_features``).\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  max_samples : int or float, default=None\n",
      " |      If bootstrap is True, the number of samples to draw from X\n",
      " |      to train each base estimator.\n",
      " |  \n",
      " |      - If None (default), then draw `X.shape[0]` samples.\n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
      " |        `max_samples` should be in the interval `(0, 1)`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  base_estimator_ : DecisionTreeRegressor\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |  estimators_ : list of DecisionTreeRegressor\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_prediction_ : ndarray of shape (n_samples,)\n",
      " |      Prediction computed with out-of-bag estimate on the training set.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DecisionTreeRegressor, ExtraTreesRegressor\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  The default value ``max_features=\"auto\"`` uses ``n_features``\n",
      " |  rather than ``n_features / 3``. The latter was originally suggested in\n",
      " |  [1], whereas the former was more recently justified empirically in [2].\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  .. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized\n",
      " |         trees\", Machine Learning, 63(1), 3-42, 2006.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestRegressor\n",
      " |  >>> from sklearn.datasets import make_regression\n",
      " |  >>> X, y = make_regression(n_features=4, n_informative=2,\n",
      " |  ...                        random_state=0, shuffle=False)\n",
      " |  >>> regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
      " |  >>> regr.fit(X, y)\n",
      " |  RandomForestRegressor(...)\n",
      " |  >>> print(regr.predict([[0, 0, 0, 0]]))\n",
      " |  [-8.32987858]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestRegressor\n",
      " |      ForestRegressor\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      BaseForest\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=100, *, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestRegressor:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict regression target for X.\n",
      " |      \n",
      " |      The predicted regression target of an input sample is computed as the\n",
      " |      mean predicted regression targets of the trees in the forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination :math:`R^2` of the\n",
      " |      prediction.\n",
      " |      \n",
      " |      The coefficient :math:`R^2` is defined as :math:`(1 - \\frac{u}{v})`,\n",
      " |      where :math:`u` is the residual sum of squares ``((y_true - y_pred)\n",
      " |      ** 2).sum()`` and :math:`v` is the total sum of squares ``((y_true -\n",
      " |      y_true.mean()) ** 2).sum()``. The best possible score is 1.0 and it\n",
      " |      can be negative (because the model can be arbitrarily worse). A\n",
      " |      constant model that always predicts the expected value of `y`,\n",
      " |      disregarding the input features, would get a :math:`R^2` score of\n",
      " |      0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator matrix where non zero elements indicates\n",
      " |          that the samples goes through the nodes. The matrix is of CSR\n",
      " |          format.\n",
      " |      \n",
      " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __annotations__ = {'_required_parameters': typing.List[str]}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d5d6a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\"n_estimators\": [i for i in range(1, 200, 5)],\n",
    "              'max_depth': [i for i in range (1, 10, 1)]\n",
    "             }\n",
    "    \n",
    "rf_model = RandomForestRegressor()\n",
    "grid_rf = GridSearchCV(rf_model,param_grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "dcfac414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'n_estimators': [1, 6, 11, 16, 21, 26, 31, 36, 41, 46,\n",
       "                                          51, 56, 61, 66, 71, 76, 81, 86, 91,\n",
       "                                          96, 101, 106, 111, 116, 121, 126, 131,\n",
       "                                          136, 141, 146, ...]})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bff88a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 46}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "805673f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = grid_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "79d45278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31504.110566437732"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5e29df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_rf = grid_rf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8460f1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame({'Id': test.Id,\n",
    "                        'SalePrice': submission})\n",
    "df_final.to_csv('E:\\Kaggle\\House Prices\\Submission_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923071f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
